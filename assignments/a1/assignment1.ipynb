{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1 | Extracting linguistic features using `spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import re\n",
    "import pandas as pd\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over each text file in the folder called `in`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(\n",
    "    \"..\",\n",
    "    \"..\",\n",
    "    \"..\",\n",
    "    \"..\",\n",
    "    \"cds-lang-data\",\n",
    "    \"USEcorpus\",\n",
    "    \"USEcorpus\",\n",
    "    \"a1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf6 in position 2640: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/work/LanguageAnalytics/cds-lang/assignments/a1/assignment1.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://app-5021893-0.cloud.sdu.dk/work/LanguageAnalytics/cds-lang/assignments/a1/assignment1.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(filepath, textfile)\n\u001b[1;32m      <a href='vscode-notebook-cell://app-5021893-0.cloud.sdu.dk/work/LanguageAnalytics/cds-lang/assignments/a1/assignment1.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filename, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m----> <a href='vscode-notebook-cell://app-5021893-0.cloud.sdu.dk/work/LanguageAnalytics/cds-lang/assignments/a1/assignment1.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     text \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m      <a href='vscode-notebook-cell://app-5021893-0.cloud.sdu.dk/work/LanguageAnalytics/cds-lang/assignments/a1/assignment1.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m cleaned_text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m<[^>]+>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, text)\n\u001b[1;32m      <a href='vscode-notebook-cell://app-5021893-0.cloud.sdu.dk/work/LanguageAnalytics/cds-lang/assignments/a1/assignment1.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m doc \u001b[39m=\u001b[39m nlp(cleaned_text)\n",
      "File \u001b[0;32m/usr/lib/python3.10/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[39m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer_decode(data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors, final)\n\u001b[1;32m    323\u001b[0m     \u001b[39m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xf6 in position 2640: invalid start byte"
     ]
    }
   ],
   "source": [
    "for textfile in os.listdir(filepath):\n",
    "    filename = os.path.join(filepath, textfile)\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "    cleaned_text = re.sub(r'<[^>]+>', '', text)\n",
    "    doc = nlp(cleaned_text)\n",
    "    adjective_count = 0\n",
    "    annotations = []\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"ADJ\":\n",
    "            adjective_count += 1\n",
    "            annotations.append((token.text, token.pos_))\n",
    "    data = pd.DataFrame(annotations, columns=[\"Tokens\", \"POS\"])\n",
    "\n",
    "    output_dir = os.path.join(\n",
    "    \"dataframes\",\n",
    "    \"annotations.csv\"\n",
    "    )\n",
    "    data.to_csv(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the following information:\n",
    "\n",
    "#### 1. Relative frequency of Nouns, Verbs, Adjective, and Adverbs per 10,000 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Total number of unique PER, LOC, ORGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. For each sub-folder (a1, a2, a3, ...) save a table which shows the following information:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
