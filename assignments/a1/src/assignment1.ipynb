{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1 | Extracting linguistic features using `spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import re\n",
    "import pandas as pd\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir_path = os.path.join(\n",
    "    \"..\",\n",
    "    \"in\"\n",
    ")\n",
    "\n",
    "input_dir = os.listdir(input_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_dir in input_dir:\n",
    "    if sub_dir == input_dir[:2]:\n",
    "        break\n",
    "    print(sub_dir)\n",
    "\n",
    "    noun_counter = 0\n",
    "    verb_counter = 0\n",
    "    adj_counter = 0\n",
    "    adv_counter = 0\n",
    "    per_counter = 0\n",
    "    loc_counter = 0\n",
    "    org_counter = 0\n",
    "\n",
    "    sub_dir_path = os.path.join(input_dir_path, sub_dir)\n",
    "\n",
    "    for txt in os.listdir(sub_dir_path):\n",
    "        txtpath = os.path.join(sub_dir_path, txt)\n",
    "        with open(txtpath, \"r\", encoding=\"iso8859_10\") as f:\n",
    "            document = f.read()\n",
    "        cleaned_text = re.sub(r'<[^>]+>', '', document)\n",
    "        doc = nlp(cleaned_text)\n",
    "\n",
    "        for token in doc:\n",
    "            if token.pos_ == \"NOUN\":\n",
    "                noun_counter += 1\n",
    "            elif token.pos_ == \"VERB\":\n",
    "                verb_counter += 1\n",
    "            elif token.pos_ == \"ADJ\":\n",
    "                adj_counter += 1\n",
    "            elif token.pos_ == \"ADV\":\n",
    "                adv_counter += 1\n",
    "\n",
    "        noun_rel_freq = round((noun_counter/len(doc) * 10000), 2)\n",
    "        verb_rel_freq = round((verb_counter/len(doc) * 10000), 2)\n",
    "        adj_rel_freq = round((adj_counter/len(doc) * 10000), 2)\n",
    "        adv_rel_freq = round((adv_counter/len(doc) * 10000), 2) \n",
    "\n",
    "        for ent in doc.ents: \n",
    "            if ent.label_ == \"PERSON\":\n",
    "                per_counter += 1\n",
    "            elif ent.label_ == \"LOC\":\n",
    "                loc_counter += 1\n",
    "            elif ent.label_ == \"ORG\":\n",
    "                org_counter += 1\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        print(txt)\n",
    "        print(noun_rel_freq)\n",
    "        print(verb_rel_freq)\n",
    "        print(adj_rel_freq)\n",
    "        print(adv_rel_freq)\n",
    "    print(f'nouns: {noun_counter}, verbs: {verb_counter}, adjectives: {adj_counter}, adverbs: {adv_counter}')\n",
    "    print(f'rel nouns: {noun_rel_freq}, rel verbs: {verb_rel_freq}, rel adjectives: {adj_rel_freq}, rel adverbs: {adv_rel_freq}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
